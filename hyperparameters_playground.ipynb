{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5382d41",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766f0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e1ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam, Ftrl, Adamax, SGD, Adadelta, Nadam, Optimizer, RMSprop, Adagrad\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard, LambdaCallback\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax, tanh, hard_sigmoid, softsign, softplus, linear\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed84cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args\n",
    "import sklearn.model_selection as sk\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4421b",
   "metadata": {},
   "source": [
    "## What versions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769571ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TensorFlow version is  2.0.0\n",
      "\n",
      "Keras version is  2.2.4-tf\n",
      "\n",
      "SciKit-optimize version is 0.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTensorFlow version is \", tf.__version__)\n",
    "print(\"\\nKeras version is \", tf.keras.__version__)\n",
    "print(\"\\nSciKit-optimize version is\",  skopt.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66bc8a7",
   "metadata": {},
   "source": [
    "## Import the data for twitter sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762871d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385042, 6)\n",
      "   Unnamed: 0          TWID       NEG       NEU       POS  \\\n",
      "0           0  7.680000e+17  0.049398  0.861395  0.089207   \n",
      "1           1  7.680000e+17  0.006598  0.046810  0.946591   \n",
      "2           2  7.680000e+17  0.032333  0.850945  0.116722   \n",
      "3           3  7.680000e+17  0.008090  0.042331  0.949579   \n",
      "4           4  7.680000e+17  0.009325  0.940488  0.050187   \n",
      "\n",
      "                                                text  \n",
      "0  #Incredible #India #Atulya #Bharat - Land of S...  \n",
      "1  RT @KendallHuntRPD: The #firstdayofschool for ...  \n",
      "2  RT @abbiesf_: Kate wrights figure is all I wan...  \n",
      "3  Josh Jenkins is looking forward to TAB Breeder...  \n",
      "4  Robert Pattinson Gets Ready to Hop on a Plane ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = '/Volumes/Elements/GitHub/twitter-project/Data Files/twitter_sentiment_learn.csv'\n",
    "\n",
    "learning_df = pd.read_csv(file)\n",
    "print(learning_df.shape)\n",
    "print(learning_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78648500",
   "metadata": {},
   "source": [
    "## Set up test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f1b7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set size:  257978\n",
      "Test-set size:   127064\n"
     ]
    }
   ],
   "source": [
    "x = learning_df['text'].to_list()\n",
    "\n",
    "\n",
    "##learning_df[[\"bad\", \"meh\", \"good\"]] = 0\n",
    "# for i in range(learning_df.shape[0]):\n",
    "# if (learning_df.loc[i,\"NEG\"] >= learning_df.loc[i,\"NEU\"]) and (learning_df.loc[i,\"NEG\"] >= learning_df.loc[i,\"POS\"]):\n",
    "##        learning_df.loc[i,\"bad\"] = 1\n",
    "# elif (learning_df.loc[i,\"NEU\"] >= learning_df.loc[i,\"NEG\"]) and (learning_df.loc[i,\"NEU\"] >= learning_df.loc[i,\"POS\"]):\n",
    "##        learning_df.loc[i,\"meh\"] = 1\n",
    "# else:\n",
    "##        learning_df.loc[i,\"good\"] = 1\n",
    "\n",
    "##y = learning_df[[\"bad\", \"meh\", \"good\"]]\n",
    "\n",
    "y = learning_df[[\"NEG\", \"NEU\", \"POS\"]]\n",
    "\n",
    "##y = tarmac\n",
    "\n",
    "x_train, x_test, y_train, y_test = sk.train_test_split(\n",
    "    x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays.\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "# print(x[1])\n",
    "\n",
    "print(\"Train-set size: \", len(x_train))\n",
    "print(\"Test-set size:  \", len(x_test))\n",
    "\n",
    "data_text = x_train + x_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48859a12",
   "metadata": {},
   "source": [
    "## Tokenization and other fun stuff for the test/train/validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3706087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be played with\n",
    "\n",
    "num_words = 30000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "\n",
    "# %%time\n",
    "tokenizer.fit_on_texts(data_text)\n",
    "\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe75c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = math.floor(max_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6c8aa",
   "metadata": {},
   "source": [
    "## More work on the tokens and the training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5905993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96db2d",
   "metadata": {},
   "source": [
    "## Set up hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4796733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Categorical(categories=[1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6],\n",
    "                                name='learning_rate')\n",
    "\n",
    "dim_num_dense_layers = Categorical(\n",
    "    categories=[1, 2, 3, 4, 5, 6], name='num_dense_layers')\n",
    "\n",
    "dim_num_dense_nodes = Categorical(\n",
    "    categories=[10, 12, 15, 19, 24, 30], name='num_dense_nodes')\n",
    "\n",
    "\n",
    "dim_activation_1 = Categorical(categories=['relu', 'sigmoid', 'softmax', 'tanh', 'hard_sigmoid',\n",
    "                                           'softsign', 'softplus', 'linear'],\n",
    "                               name='activation_1')\n",
    "dim_activation_2 = Categorical(categories=['relu', 'sigmoid', 'softmax', 'tanh', 'hard_sigmoid',\n",
    "                                           'softsign', 'softplus', 'linear'],\n",
    "                               name='activation_2')\n",
    "\n",
    "dim_recurrent_1 = Categorical(categories=['relu', 'sigmoid', 'softmax', 'tanh', 'hard_sigmoid',\n",
    "                                          'softsign', 'softplus', 'linear'],\n",
    "                              name='recurrent_activation_1')\n",
    "\n",
    "dim_recurrent_2 = Categorical(categories=['relu', 'sigmoid', 'softmax', 'tanh', 'hard_sigmoid',\n",
    "                                          'softsign', 'softplus', 'linear'],\n",
    "                              name='recurrent_activation_2')\n",
    "\n",
    "dim_batches_yo = size = Categorical(\n",
    "    categories=[128, 160, 192, 256, 384, 512],  name='batchez_yo')\n",
    "\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation_1,\n",
    "              dim_activation_2,\n",
    "              dim_recurrent_1,\n",
    "              dim_recurrent_2,\n",
    "              dim_batches_yo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6645c7",
   "metadata": {},
   "source": [
    "## Starting values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c46853",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = [1e-3, 3, 10, 'softplus',\n",
    "                      'relu', 'sigmoid', 'softsign', 128]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf515ba",
   "metadata": {},
   "source": [
    "## Now the optimizing function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a30ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_of_merit = 2 * max_tokens  # was 100\n",
    "first_layer = math.floor(max_tokens/2) + 2\n",
    "second_layer = math.floor(max_tokens/3) + 2\n",
    "third_layer = math.floor(max_tokens/4) + 3\n",
    "fourth_layer = math.floor(max_tokens/5) + 3\n",
    "embedding_size = figure_of_merit\n",
    "\n",
    "\n",
    "def log_dir_name(learning_rate,\n",
    "                 num_dense_layers,\n",
    "                 num_dense_nodes,\n",
    "                 activation_1,\n",
    "                 activation_2,\n",
    "                 recurrent_activation_1,\n",
    "                 recurrent_activation_2,\n",
    "                 batchez_yo):\n",
    "    # ,\n",
    " # optimizations_yo):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./19_logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n",
    "\n",
    "    # Insert all the hyper-parameters in the dir-name.\n",
    "    log_dir = s.format(learning_rate,\n",
    "                       num_dense_layers,\n",
    "                       num_dense_nodes,\n",
    "                       activation_1,\n",
    "                       activation_2,\n",
    "                       recurrent_activation_1,\n",
    "                       recurrent_activation_2,\n",
    "                       batchez_yo)\n",
    "    # ,\n",
    "    # optimizations_yo)\n",
    "    tf.autograph.experimental.do_not_convert(\n",
    "        func=None)\n",
    "\n",
    "    return log_dir\n",
    "\n",
    "\n",
    "def create_model(learning_rate,\n",
    "                 num_dense_layers,\n",
    "                 num_dense_nodes,\n",
    "                 activation_1,\n",
    "                 activation_2,\n",
    "                 recurrent_activation_1,\n",
    "                 recurrent_activation_2,\n",
    "                 batchez_yo):\n",
    "    # ,\n",
    "    # optimizations_yo):\n",
    "\n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    # Note that the input-shape must be a tuple containing the image-size.\n",
    "    model.add(Embedding(input_dim=num_words,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_tokens,\n",
    "                        name='layer_embedding'))\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "    # Put in the GRU flavor\n",
    "    model.add(GRU(units=first_layer, activation=activation_1,\n",
    "                  recurrent_activation=recurrent_activation_1, return_sequences=True))\n",
    "\n",
    "    i = 0\n",
    "    j = num_dense_layers\n",
    "    while i < j:\n",
    "        model.add(GRU(units=math.floor(max_tokens/(i+2)) + 2, activation=activation_2,\n",
    "                      recurrent_activation=recurrent_activation_2, return_sequences=True))\n",
    "        i = i + 1\n",
    "\n",
    "    model.add(GRU(units=fourth_layer, activation=activation_1,\n",
    "                  recurrent_activation=recurrent_activation_1, return_sequences=False))\n",
    "    # , return_sequences = False))\n",
    "\n",
    "    model.add(Dense(3, activation=activation_2))  # was 3\n",
    "\n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    # if optimizations_yo == 1:\n",
    "    ##    optimizer = Adadelta(lr=learning_rate)\n",
    "    ##  print(\"Optimizer is Adadelta.\")\n",
    "   # elif optimizations_yo == 2:\n",
    "   ##     optimizer = Adagrad(lr=learning_rate)\n",
    "   ##     print(\"Optimizer is Adagrad.\")\n",
    "    # elif optimizations_yo == 3:\n",
    "    ##    optimizer = Adam(lr=learning_rate)\n",
    "    ##    print(\"Optimizer is Adam.\")\n",
    "    # elif optimizations_yo == 4:\n",
    "    ##    optimizer = Adamax(lr=learning_rate)\n",
    "    ##    print(\"Optimizer is Adamax.\")\n",
    "    # else:\n",
    "    ##    optimizer = Nadam(lr=learning_rate)\n",
    "    ##    print(\"Optimizer is Nadam.\")\n",
    "\n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    optimizering = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizering,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tf.autograph.experimental.do_not_convert(\n",
    "        func=None)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd80e8",
   "metadata": {},
   "source": [
    "## Now to make it more Gated and so on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ac209",
   "metadata": {},
   "source": [
    "## Train and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36b0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_best_model = '19_best_model.h5'\n",
    "\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "##validation_data = (data.x_val, data.y_val)\n",
    "\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate,\n",
    "            num_dense_layers,\n",
    "            num_dense_nodes,\n",
    "            activation_1,\n",
    "            activation_2,\n",
    "            recurrent_activation_1,\n",
    "            recurrent_activation_2,\n",
    "            batchez_yo):\n",
    "    # ,\n",
    "    # optimizations_yo):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "    tf.autograph.experimental.do_not_convert(\n",
    "        func=None)\n",
    "\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation_1=activation_1,\n",
    "                         activation_2=activation_2,\n",
    "                         recurrent_activation_1=recurrent_activation_1,\n",
    "                         recurrent_activation_2=recurrent_activation_2,\n",
    "                         batchez_yo=batchez_yo)\n",
    "    # ,\n",
    "    # optimizations_yo = optimizations_yo)\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(learning_rate,\n",
    "                           num_dense_layers,\n",
    "                           num_dense_nodes,\n",
    "                           activation_1,\n",
    "                           activation_2,\n",
    "                           recurrent_activation_1,\n",
    "                           recurrent_activation_2,\n",
    "                           batchez_yo)\n",
    "    # ,\n",
    "    # optimizations_yo)\n",
    "\n",
    "    # Create a callback-function for Keras which will be\n",
    "    # run after each epoch has ended during training.\n",
    "    # This saves the log-files for TensorBoard.\n",
    "    # Note that there are complications when histogram_freq=1.\n",
    "    # It might give strange errors and it also does not properly\n",
    "    # support Keras data-generators for the validation-set.\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "\n",
    "    callbackx = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                 patience=0,\n",
    "                                                 restore_best_weights=True)\n",
    " # Not used in this version\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('val_accuracy') > 0.95):\n",
    "                print(\n",
    "                    \"\\nReached 95% validation accuracy, so changing the optimizer to Nadam.\")\n",
    "                optimizer = Nadam(learning_rate=learning_rate/5)\n",
    "                self.model.stop_training = False\n",
    "            if(logs.get('val_accuracy') > 0.97):\n",
    "                print(\n",
    "                    \"\\nReached 97% validation accuracy, so changing the optimizer to Adadelta.\")\n",
    "                optimizer = Adadelta(learning_rate=learning_rate/10)\n",
    "                self.model.stop_training = False\n",
    "\n",
    "    call_it = myCallback()\n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=x_train_pad,\n",
    "                        y=y_train,\n",
    "                        epochs=8,\n",
    "                        batch_size=batchez_yo,\n",
    "                        validation_split=0.3,\n",
    "                        callbacks=[callback_log, callbackx, call_it])\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-2]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print('+++++++++++++++++++++++++++')\n",
    "    print('Accuracy: {0:.2%}'.format(accuracy))\n",
    "    print('@@@@@@@@@@@@@@@@@@@@@')\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation_1:', activation_1)\n",
    "    print('activation_2:', activation_2)\n",
    "    print('recurrent_activation_1:', recurrent_activation_1)\n",
    "    print('recurrent_activation_2:', recurrent_activation_2)\n",
    "    print('batches are ', batchez_yo)\n",
    "    print('********************')\n",
    "    print('The model summary is ', model.summary)\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if accuracy > best_accuracy:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "\n",
    "        # Update the classification accuracy.\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "\n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "\n",
    "    return -accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d41485",
   "metadata": {},
   "source": [
    "## Is this the test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af253b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 13:33:13.314406: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-18 13:33:13.314824: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   128/180584 [..............................] - ETA: 4:23:03 - loss: 5.0330 - accuracy: 0.7266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 13:33:25.191284: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 560s 3ms/sample - loss: nan - accuracy: 0.3261 - val_loss: nan - val_accuracy: 0.0581\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 496s 3ms/sample - loss: nan - accuracy: 0.0568 - val_loss: nan - val_accuracy: 0.0581\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 5.81%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 1.0e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 10\n",
      "activation_1: softplus\n",
      "activation_2: relu\n",
      "recurrent_activation_1: sigmoid\n",
      "recurrent_activation_2: softsign\n",
      "batches are  128\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f83e253acd0>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   256/180584 [..............................] - ETA: 1:45:40 - loss: 9.0719 - accuracy: 0.1328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 13:51:00.446913: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 280s 2ms/sample - loss: nan - accuracy: 0.4446 - val_loss: nan - val_accuracy: 0.0581\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 275s 2ms/sample - loss: nan - accuracy: 0.0568 - val_loss: nan - val_accuracy: 0.0581\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 5.81%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 1.0e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 19\n",
      "activation_1: linear\n",
      "activation_2: relu\n",
      "recurrent_activation_1: linear\n",
      "recurrent_activation_2: softsign\n",
      "batches are  256\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f83b3b27cd0>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   256/180584 [..............................] - ETA: 3:04:38 - loss: 6.8343 - accuracy: 0.1680"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 14:00:22.929162: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 398s 2ms/sample - loss: 2.8987 - accuracy: 0.5910 - val_loss: 9.3563 - val_accuracy: 0.6099\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 426s 2ms/sample - loss: 8.6417 - accuracy: 0.6098 - val_loss: 9.2372 - val_accuracy: 0.6099\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 60.99%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 5.0e-05\n",
      "num_dense_layers: 6\n",
      "num_dense_nodes: 12\n",
      "activation_1: linear\n",
      "activation_2: linear\n",
      "recurrent_activation_1: sigmoid\n",
      "recurrent_activation_2: softplus\n",
      "batches are  256\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f5d61989ad0>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   384/180584 [..............................] - ETA: 57:56 - loss: 1.0653 - accuracy: 0.6198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 14:13:59.042673: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 186s 1ms/sample - loss: 1.0498 - accuracy: 0.6089 - val_loss: 1.0305 - val_accuracy: 0.6099\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 192s 1ms/sample - loss: 0.9949 - accuracy: 0.6089 - val_loss: 0.9360 - val_accuracy: 0.6099\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 60.99%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 5.0e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 19\n",
      "activation_1: relu\n",
      "activation_2: hard_sigmoid\n",
      "recurrent_activation_1: softmax\n",
      "recurrent_activation_2: softmax\n",
      "batches are  384\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f58f31495d0>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   160/180584 [..............................] - ETA: 2:32:35 - loss: 1.3058 - accuracy: 0.0437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 14:20:18.539849: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 406s 2ms/sample - loss: 1.2195 - accuracy: 0.0568 - val_loss: 1.1478 - val_accuracy: 0.0581\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 408s 2ms/sample - loss: 1.0895 - accuracy: 0.3977 - val_loss: 1.0354 - val_accuracy: 0.6099\n",
      "Epoch 3/8\n",
      "180584/180584 [==============================] - 440s 2ms/sample - loss: 0.9894 - accuracy: 0.6089 - val_loss: 0.9476 - val_accuracy: 0.6099\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 60.99%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 1.0e-05\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 19\n",
      "activation_1: softplus\n",
      "activation_2: softplus\n",
      "recurrent_activation_1: softsign\n",
      "recurrent_activation_2: softmax\n",
      "batches are  160\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f591ac10d50>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   160/180584 [..............................] - ETA: 4:22:02 - loss: nan - accuracy: 0.0437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 14:41:20.800012: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 539s 3ms/sample - loss: nan - accuracy: 0.0568 - val_loss: nan - val_accuracy: 0.0581\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 568s 3ms/sample - loss: nan - accuracy: 0.0568 - val_loss: nan - val_accuracy: 0.0581\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 5.81%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 1.0e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 19\n",
      "activation_1: tanh\n",
      "activation_2: softplus\n",
      "recurrent_activation_1: softsign\n",
      "recurrent_activation_2: softplus\n",
      "batches are  160\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f656e325e90>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   160/180584 [..............................] - ETA: 2:44:24 - loss: 1.0184 - accuracy: 0.3187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 14:59:43.860494: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 403s 2ms/sample - loss: 0.9959 - accuracy: 0.3343 - val_loss: 0.9770 - val_accuracy: 0.3320\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 536s 3ms/sample - loss: 0.9585 - accuracy: 0.3343 - val_loss: 0.9434 - val_accuracy: 0.3320\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 33.20%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 5.0e-06\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 15\n",
      "activation_1: sigmoid\n",
      "activation_2: relu\n",
      "recurrent_activation_1: sigmoid\n",
      "recurrent_activation_2: softmax\n",
      "batches are  160\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7ec657147d90>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   384/180584 [..............................] - ETA: 1:41:13 - loss: nan - accuracy: 0.0495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 15:15:28.784187: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 259s 1ms/sample - loss: nan - accuracy: 0.0568 - val_loss: nan - val_accuracy: 0.0581\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 244s 1ms/sample - loss: nan - accuracy: 0.0568 - val_loss: nan - val_accuracy: 0.0581\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 5.81%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 5.0e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 15\n",
      "activation_1: softmax\n",
      "activation_2: sigmoid\n",
      "recurrent_activation_1: softplus\n",
      "recurrent_activation_2: softplus\n",
      "batches are  384\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f591cce5710>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   128/180584 [..............................] - ETA: 5:47:40 - loss: 1.1982 - accuracy: 0.0469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 15:23:54.323692: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 609s 3ms/sample - loss: 1.1430 - accuracy: 0.3161 - val_loss: 1.0704 - val_accuracy: 0.3320\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 638s 4ms/sample - loss: 1.0174 - accuracy: 0.3343 - val_loss: 0.9666 - val_accuracy: 0.3320\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 33.20%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 1.0e-05\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 10\n",
      "activation_1: softsign\n",
      "activation_2: softplus\n",
      "recurrent_activation_1: linear\n",
      "recurrent_activation_2: hard_sigmoid\n",
      "batches are  128\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7e48cf537fd0>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   256/180584 [..............................] - ETA: 2:00:27 - loss: 5.1655 - accuracy: 0.1602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 15:44:37.511164: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 239s 1ms/sample - loss: 1.8504 - accuracy: 0.0571 - val_loss: 1.8820 - val_accuracy: 0.0581\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 220s 1ms/sample - loss: 1.8504 - accuracy: 0.0568 - val_loss: 1.8820 - val_accuracy: 0.0581\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 5.81%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 5.0e-04\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 10\n",
      "activation_1: tanh\n",
      "activation_2: linear\n",
      "recurrent_activation_1: softplus\n",
      "recurrent_activation_2: hard_sigmoid\n",
      "batches are  256\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7e22a8dd8e10>>\n",
      "Train on 180584 samples, validate on 77394 samples\n",
      "Epoch 1/8\n",
      "   512/180584 [..............................] - ETA: 1:33:57 - loss: 1.0114 - accuracy: 0.3555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 15:52:23.266655: I tensorflow/core/profiler/lib/profiler_session.cc:184] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180584/180584 [==============================] - 241s 1ms/sample - loss: 0.8898 - accuracy: 0.5763 - val_loss: 0.8735 - val_accuracy: 0.6099\n",
      "Epoch 2/8\n",
      "180584/180584 [==============================] - 260s 1ms/sample - loss: 0.8722 - accuracy: 0.6089 - val_loss: 0.8734 - val_accuracy: 0.6099\n",
      "+++++++++++++++++++++++++++\n",
      "Accuracy: 60.99%\n",
      "@@@@@@@@@@@@@@@@@@@@@\n",
      "learning rate: 1.0e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 12\n",
      "activation_1: relu\n",
      "activation_2: hard_sigmoid\n",
      "recurrent_activation_1: sigmoid\n",
      "recurrent_activation_2: relu\n",
      "batches are  512\n",
      "********************\n",
      "The model summary is  <bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7e43028f6350>>\n",
      "CPU times: user 7h 38min 31s, sys: 20h 4min 42s, total: 1d 3h 43min 13s\n",
      "Wall time: 2h 27min 15s\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI',  # Expected of improvement.\n",
    "                            n_calls=11,\n",
    "                            x0=default_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "841fbe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the date and time is  2022-06-18 16:00:29.163446\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "print(\"the date and time is \", time_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9f586",
   "metadata": {},
   "source": [
    "## Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a4fd47",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3q/y2fjlm8n4752m4cv89kq3r0h0000gn/T/ipykernel_92009/2480159394.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msearch_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_best_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m result = model.evaluate(x= x_test_pad,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/for_tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/for_tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m    168\u001b[0m                                                custom_objects=custom_objects)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(search_result)\n",
    "\n",
    "search_result.x\n",
    "\n",
    "model = load_model(path_best_model)\n",
    "\n",
    "result = model.evaluate(x=x_test_pad,\n",
    "                        y=y_test)\n",
    "\n",
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3daa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "default_parameters_1 = [1e-6, 6, 30, 'linear',\n",
    "                        'linear', 'linear', 'linear', 512]\n",
    "\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='LCB',  # Lower Confidence Bound.\n",
    "                            n_calls=12,\n",
    "                            x0=default_parameters_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16792ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "print(\"the date and time is \", time_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(search_result)\n",
    "\n",
    "search_result.x\n",
    "\n",
    "model = load_model(path_best_model)\n",
    "\n",
    "result = model.evaluate(x=x_test_pad,\n",
    "                        y=y_test)\n",
    "\n",
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440994e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "default_parameters_2 = [1e-5, 3, 10, 'sigmoid', 'sigmoid', 'relu', 'relu', 256]\n",
    "\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='gp_hedge',  # Probability of improvement.\n",
    "                            n_calls=12,\n",
    "                            x0=default_parameters_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da309826",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "print(\"the date and time is \", time_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f368cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(search_result)\n",
    "\n",
    "search_result.x\n",
    "\n",
    "model = load_model(path_best_model)\n",
    "\n",
    "result = model.evaluate(x=x_test_pad,\n",
    "                        y=y_test)\n",
    "\n",
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1fe701",
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "default_parameters_3 = [1e-5, 3, 10, 'softmax',\n",
    "                        'sigmoid', 'relu', 'softmax', 384]\n",
    "\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='gp_hedge',  # Hedge of the above 3.\n",
    "                            n_calls=10\\2,\n",
    "                            x0=default_parameters_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "print(\"the date and time is \", time_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a881f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_convergence(search_result)\n",
    "\n",
    "search_result.x\n",
    "\n",
    "model = load_model(path_best_model)\n",
    "\n",
    "result = model.evaluate(x=x_test_pad,\n",
    "                        y=y_test)\n",
    "\n",
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449e860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('for_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "15723ea50007c9eb518e398a0ca0130bc4bd2586315387ed6566b7a3b6eabae5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

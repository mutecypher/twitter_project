{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63a22374",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9db7632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.backend import square, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e1ba9",
   "metadata": {},
   "source": [
    "## Now get the files with the first and the last kept duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23a8c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_first = ['//Volumes/Elements/GitHub/twitter-project/Data Files/CRWD_first_kept_preproc.csv',\n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/APPN_first_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/INSP_first_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/SNY_first_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/EVBG_first_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/KMI_first_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/Amazon_first_kept_preproc.csv',\n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/Exxon_first_kept_preproc.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1da69bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_last = ['/Volumes/Elements/GitHub/twitter-project/Data Files/CRWD_last_kept_preproc.csv',\n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/APPN_last_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/INSP_last_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/SNY_last_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/EVBG_last_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/KMI_last_kept_preproc.csv', \n",
    "'/Volumes/Elements/GitHub/twitter-project/Data Files/Amazon_last_kept_preproc.csv',\n",
    "'/Volumes/Elements/GitHub/twitter-project/Data FilesExxon_last_kept_preproc.csv']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5321c78",
   "metadata": {},
   "source": [
    "## Now hose with the number of days to predict ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0b9fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shift the number of days\n",
    "shift_days = 1\n",
    "shift_steps = shift_days * 24  # Number of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba414a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 14)\n",
      "         date  flat_avg_neg  flat_avg_neu  flat_avg_pos  number_of_same_dates  \\\n",
      "0  2020-06-24      0.081976      0.454402      0.463622                 314.0   \n",
      "1  2020-06-25      0.076232      0.540759      0.383009                 856.0   \n",
      "2  2020-06-26      0.092678      0.559408      0.347915                 107.0   \n",
      "3  2020-06-27      0.061732      0.715758      0.222509                  20.0   \n",
      "4  2020-06-28      0.101550      0.460008      0.438442                  23.0   \n",
      "\n",
      "   weighted_avg_neg  weighted_avg_neu  weighted_avg_pos   min_neg   min_neu  \\\n",
      "0          0.102342          0.410040          0.487618  0.000464  0.001805   \n",
      "1          0.112850          0.520682          0.366468  0.000441  0.001772   \n",
      "2          0.126983          0.475099          0.397917  0.000726  0.002264   \n",
      "3          0.022118          0.679987          0.297890  0.001158  0.005275   \n",
      "4          0.080943          0.545341          0.373712  0.000965  0.004019   \n",
      "\n",
      "    min_pos   max_neg   max_neu   max_pos  \n",
      "0  0.001615  0.981268  0.990884  0.997731  \n",
      "1  0.001856  0.990294  0.991422  0.997722  \n",
      "2  0.001828  0.988336  0.991145  0.997010  \n",
      "3  0.007420  0.635762  0.989122  0.993567  \n",
      "4  0.006792  0.964538  0.990157  0.995016  \n"
     ]
    }
   ],
   "source": [
    "amzn_df = pd.read_csv('/Volumes/Elements/GitHub/twitter-project/Data Files/Amazon_first_kept_preproc.csv', header='infer', index_col=0, parse_dates=True)\n",
    "print(amzn_df.shape)\n",
    "print(amzn_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f745e9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 14)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets = amzn_df.shift(-shift_days)\n",
    "df_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a08f8382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_cols = amzn_df[[\"date\",\"weighted_avg_neg\", \"weighted_avg_neu\", \"weighted_avg_pos\"]]\n",
    "y_data = y_cols.values[:-shift_days]\n",
    "print(type(y_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c619405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Shape is  (232, 14)\n"
     ]
    }
   ],
   "source": [
    "x_data = amzn_df.values[0:-shift_days]\n",
    "print(type(x_data))\n",
    "print(\"\\nShape is \", x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104f41b",
   "metadata": {},
   "source": [
    "## Now get the data from the yahoo pricing file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b013f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 41)\n"
     ]
    }
   ],
   "source": [
    "amzn_price = pd.read_csv('/Volumes/Elements/GitHub/twitter-project/Data Files/amzn_stock_df.csv',header='infer', index_col=0, parse_dates=True)\n",
    "print(amzn_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bacc963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  formatted_date       pct\n",
      "0     2020-03-25 -0.027968\n",
      "1     2020-03-26  0.036933\n",
      "2     2020-03-27 -0.028325\n",
      "3     2020-03-30  0.033603\n",
      "4     2020-03-31 -0.007246\n"
     ]
    }
   ],
   "source": [
    "prices = amzn_price[[\"formatted_date\",\"pct\"]]\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff92c7",
   "metadata": {},
   "source": [
    "## Now let's import the stock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77b40d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data = ['/Volumes/Elements/GitHub/twitter-project/Data Files/amzn_stock_df.csv',\n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Filestsla_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/appl_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/evbg_stock_df.csv'\n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/kmi_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/shop_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/gmed_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/sny_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/mck_stock_df.csv',\n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Fileset_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/insp_stock_df.csv',\n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/crwd_stock_df.csv',\n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/clf_stock_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/UVXY_etf_df.csv', \n",
    "               '//Volumes/Elements/GitHub/twitter-project/Data FilesGLD_etf_df.csv', \n",
    "               '/Volumes/Elements/GitHub/twitter-project/Data Files/GBTC_etf_df.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72547587",
   "metadata": {},
   "source": [
    "## Deal with the missing days of the week - in stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5dba3c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " the count is  0\n",
      "\n",
      " the one zed is  0\n",
      "\n",
      " the zed one is  0\n",
      "\n",
      " the ones is  16\n",
      "\n",
      " the onestwos is  17\n",
      "\n",
      " the two ones is  17\n",
      "\n",
      " the two two is  0\n",
      "\n",
      " the head for the new data frame is \n",
      "           date       pct\n",
      "0  2020-06-24 -0.010856\n",
      "1  2020-06-25  0.007380\n",
      "2  2020-06-26 -0.022403\n",
      "3  2020-06-27       NaN\n",
      "4  2020-06-28       NaN\n",
      "\n",
      " the tail for the new data frame is \n",
      "             date       pct\n",
      "221  2021-08-16  0.001524\n",
      "222  2021-08-17 -0.017287\n",
      "223  2021-08-18 -0.012566\n",
      "224  2021-08-20  0.003827\n",
      "225  2021-08-21       NaN\n",
      "226  2021-08-22       NaN\n",
      "227  2021-08-23  0.020600\n",
      "228  2021-08-28       NaN\n",
      "229  2021-08-29       NaN\n",
      "230  2021-08-30  0.021477\n"
     ]
    }
   ],
   "source": [
    "new_amzn_dates = pd.DataFrame()\n",
    "##print(\"\\n number of twitter dates is \", amzn_df.shape)\n",
    "##print(\"\\n number of stock dates is \", amzn_price.shape)\n",
    "##print(\"\\n head of twitter dates is \", amzn_df.head())\n",
    "##print(\"\\n head of stock dates is \", amzn_price.head())\n",
    "##print(\"\\n tale of twitter dates is \", amzn_df.tail())\n",
    "##print(\"\\n tale of stock dates is \", amzn_price.tail())\n",
    "\n",
    "county = 0\n",
    "ones = 0\n",
    "ones_twos = 0\n",
    "twos_ones = 0\n",
    "two_two = 0\n",
    "one_zed = 0\n",
    "zed_one = 0\n",
    "if amzn_df.shape[0] <= amzn_price.shape[0]:\n",
    "    bobby = amzn_df.shape[0] - 2\n",
    "else:\n",
    "    bobby = amzn_price.shape[0] - 2\n",
    "for datez in range(bobby):\n",
    "    if amzn_price.loc[datez,\"formatted_date\"] == amzn_df.loc[datez,\"date\"]:\n",
    "        new_amzn_dates.loc[datez,\"date\"] = amzn_df.loc[datez,\"date\"]\n",
    "        new_amzn_dates.loc[datez,\"pct\"] = amzn_price.loc[datez,\"pct\"]\n",
    "        county += 1\n",
    "##        print(\"date is \", amzn_df.loc[datez,\"date\"], \"and the index number is \", datez)\n",
    "    else:\n",
    "        new_amzn_dates.loc[datez, \"date\"] = amzn_df.loc[datez,\"date\"]\n",
    "        if any (amzn_price.formatted_date == amzn_df.loc[datez,\"date\"]):\n",
    "            \n",
    "            new_amzn_dates.loc[datez, \"pct\"] = amzn_price.loc[amzn_price.index[amzn_price['formatted_date'] ==  amzn_df.loc[datez,\"date\"]].tolist()[0], \"pct\"]\n",
    "        elif any(amzn_price.formatted_date == amzn_df.loc[datez-1,\"date\"]) and any(amzn_price.formatted_date == amzn_df.loc[datez+1,\"date\"]):  \n",
    "##            print(\"one and one\")\n",
    "            ones += 1\n",
    "##            new_amzn_dates.loc[datez, \"pct\"] = amzn_price.loc[amzn_price.index[amzn_price['formatted_date'] ==  amzn_df.loc[datez,\"date\"]].tolist()[0], \"pct\"]\n",
    "        elif any(amzn_price.formatted_date == amzn_df.loc[datez-1,\"date\"]) and any(amzn_price.formatted_date == amzn_df.loc[datez+2,\"date\"]):\n",
    "##            print(\"one and two\")\n",
    "            ones_twos += 1\n",
    "        elif any(amzn_price.formatted_date == amzn_df.loc[datez-2,\"date\"]) and any(amzn_price.formatted_date == amzn_df.loc[datez+1,\"date\"]):\n",
    "##            print(\"two and one\")\n",
    "            twos_ones += 1\n",
    "        elif any(amzn_price.formatted_date == amzn_df.loc[datez-2,\"date\"]) and any(amzn_price.formatted_date == amzn_df.loc[datez+2,\"date\"]):\n",
    "##            print(\"two and two\")\n",
    "            two_two += 1\n",
    "        elif any(amzn_price.formatted_date == amzn_df.loc[datez-1,\"date\"]) and any(amzn_price.formatted_date == amzn_df.loc[datez+3,\"date\"]): \n",
    "            one_zed += 1\n",
    "        ##elif any(amzn_price.formatted_date == amzn_df.loc[datez+3,\"date\"]) and any(amzn_price.formatted_date == amzn_df.loc[datez-1,\"date\"]): \n",
    "          ##  ozed_one += 1   \n",
    "            \n",
    "print(\"\\n the count is \", county)\n",
    "print(\"\\n the one zed is \", one_zed)\n",
    "print(\"\\n the zed one is \", zed_one)\n",
    "print(\"\\n the ones is \", ones)\n",
    "print(\"\\n the onestwos is \", ones_twos)\n",
    "print(\"\\n the two ones is \", twos_ones)\n",
    "print(\"\\n the two two is \", two_two)\n",
    "\n",
    "\n",
    "print(\"\\n the head for the new data frame is \\n \", new_amzn_dates.head())\n",
    "print(\"\\n the tail for the new data frame is \\n \", new_amzn_dates.tail(10))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f75bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  flat_avg_neg  flat_avg_neu  flat_avg_pos  number_of_same_dates  \\\n",
      "5  2020-06-29      0.049641      0.547178      0.403181                 112.0   \n",
      "\n",
      "   weighted_avg_neg  weighted_avg_neu  weighted_avg_pos   min_neg  min_neu  \\\n",
      "5          0.020339           0.43734           0.54232  0.000528  0.00229   \n",
      "\n",
      "    min_pos  max_neg   max_neu   max_pos  \n",
      "5  0.002316  0.98605  0.990433  0.996592  \n",
      "           high          low        open        close   volume     adjclose  \\\n",
      "66  2696.800049  2630.080078  2690.01001  2680.379883  4223400  2680.379883   \n",
      "\n",
      "   formatted_date       pct  rolling3  var3  ...  rolling50  varfifty  \\\n",
      "66     2020-06-29 -0.004638 -0.006554     0  ...     0.0026         0   \n",
      "\n",
      "    covarfifty  betafifty  rolling250  varyear  covaryear  betayr_clf  \\\n",
      "66           0          0    0.005076        0          0           0   \n",
      "\n",
      "    betayr_ndaq  betayr_djia  \n",
      "66            0            0  \n",
      "\n",
      "[1 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(amzn_df.loc[amzn_df['date']== '2020-06-29'])\n",
    "print(amzn_price.loc[amzn_price['formatted_date']== '2020-06-29'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a83a646c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (9711008.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/3q/y2fjlm8n4752m4cv89kq3r0h0000gn/T/ipykernel_15618/9711008.py\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    idx = amzn_df.index()____ .tolist()\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "new_amzn_dates = pd.DataFrame()\n",
    "##print(\"\\n number of twitter dates is \", amzn_df.shape)\n",
    "##print(\"\\n number of stock dates is \", amzn_price.shape)\n",
    "##print(\"\\n head of twitter dates is \", amzn_df.head())\n",
    "##print(\"\\n head of stock dates is \", amzn_price.head())\n",
    "##print(\"\\n tale of twitter dates is \", amzn_df.tail())\n",
    "##print(\"\\n tale of stock dates is \", amzn_price.tail())\n",
    "\n",
    "county = 0\n",
    "ones = 0\n",
    "ones_twos = 0\n",
    "twos_ones = 0\n",
    "two_two = 0\n",
    "one_zed = 0\n",
    "zed_one = 0\n",
    "\n",
    "for datez in amzn_df.date:\n",
    "    if any (amzn_price.formatted_date == datez):\n",
    "        idx = amzn_df.index()____ .tolist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amzn_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d1162-8b4f-46be-80ee-c62e474d8413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

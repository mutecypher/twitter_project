{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the needed items and then get to analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-16\n",
      "2020-03-24\n",
      "earliest date should be 3-24-2020\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from yahoofinancials import YahooFinancials\n",
    "import datetime\n",
    "import statistics as st\n",
    "import numpy as np\n",
    "##import json\n",
    "whats_today = datetime.datetime.now().date()\n",
    "\n",
    "## add a day for every day past October 31, 2021 - was 586\n",
    "\n",
    "minus_fifteen_years =  whats_today - datetime.timedelta(days = 828 + 16) ## for July 2022 plus day of month\n",
    "\n",
    "##whats_today = whats_today.date()\n",
    "##minus_three = minus_three.date\n",
    "whats_today = whats_today.strftime('%Y-%m-%d')\n",
    "minus_fifteen_years = minus_fifteen_years.strftime('%Y-%m-%d')\n",
    "print(whats_today)\n",
    "print(minus_fifteen_years)\n",
    "\n",
    "print(\"earliest date should be 3-24-2020\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the SP 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 7)\n",
      "(583, 7)\n",
      "(583, 7)\n",
      "\n",
      "this finished at  2022-07-16 14:52:50.044063\n",
      "the head of sp500_df is \n",
      "           high          low         open        close      volume  \\\n",
      "0  2571.419922  2407.530029  2457.770020  2475.560059  8285670000   \n",
      "1  2615.909912  2520.020020  2555.870117  2541.469971  6194330000   \n",
      "2  2631.800049  2545.280029  2558.979980  2626.649902  5746220000   \n",
      "3  2641.389893  2571.149902  2614.689941  2584.590088  6568290000   \n",
      "4  2522.750000  2447.489990  2498.080078  2470.500000  5947900000   \n",
      "\n",
      "      adjclose formatted_date       pct  rolling3      var3  ...  covar30  \\\n",
      "0  2475.560059     2020-03-25  0.011535  0.011535  0.000000  ...      0.0   \n",
      "1  2541.469971     2020-03-27 -0.033687  0.013421  0.002312  ...      0.0   \n",
      "2  2626.649902     2020-03-30  0.033516  0.020748  0.002431  ...      0.0   \n",
      "3  2584.590088     2020-03-31 -0.016013 -0.005395  0.001214  ...      0.0   \n",
      "4  2470.500000     2020-04-01 -0.044142 -0.008880  0.001546  ...      0.0   \n",
      "\n",
      "   beta30  rolling50  varfifty  covarfifty  betafifty  rolling250  var250  \\\n",
      "0     0.0   0.011535       0.0         0.0        0.0    0.011535     0.0   \n",
      "1     0.0   0.013421       0.0         0.0        0.0    0.013421     0.0   \n",
      "2     0.0   0.018444       0.0         0.0        0.0    0.018444     0.0   \n",
      "3     0.0   0.011553       0.0         0.0        0.0    0.011553     0.0   \n",
      "4     0.0   0.002270       0.0         0.0        0.0    0.002270     0.0   \n",
      "\n",
      "   covar250  beta250  \n",
      "0       0.0      0.0  \n",
      "1       0.0      0.0  \n",
      "2       0.0      0.0  \n",
      "3       0.0      0.0  \n",
      "4       0.0      0.0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "marketz = ['DJIA','NDAQ','^GSPC']\n",
    "namez = [ 'djia_df', 'nasdaq_df', 'spy_df']\n",
    "\n",
    "\n",
    "i =0\n",
    "for market in marketz:\n",
    "    yahoo_financials = YahooFinancials(market)\n",
    "\n",
    "    data = yahoo_financials.get_historical_price_data(start_date= minus_fifteen_years, \n",
    "                                                  end_date= whats_today, \n",
    "                                                  time_interval='daily')\n",
    "   \n",
    "    namez[i] = pd.DataFrame(data[market]['prices'])\n",
    "    namez[i] = namez[i].drop('date', axis=1)\n",
    "    print(namez[i].shape)\n",
    "\n",
    "    barky = namez[i]['adjclose']\n",
    "    namez[i]['pct'] = barky.pct_change(1)\n",
    "    roll_3_am =namez[i]['pct'].rolling(3, min_periods = 1).mean()\n",
    "    namez[i]['rolling3'] = roll_3_am\n",
    "\n",
    "\n",
    "    \n",
    "    ## three day rolling averages\n",
    "    namez[i]['var3'] = 0\n",
    "    namez[i]['covar3'] = 0\n",
    "    namez[i]['beta3'] = 0\n",
    "    namez[i]['var10'] = 0\n",
    "    namez[i]['covar10']= 0\n",
    "    namez[i]['beta10'] = 0\n",
    "    for j in range(2, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'var3'] = namez[i].loc[j-2:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar3']= np.cov(namez[i].loc[j-2:j,'pct'], namez[i].loc[j-2:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar3'] != 0:\n",
    "            namez[i].loc[j,'beta3'] = namez[i].loc[j,'covar3']/namez[i].loc[j,'var3']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta3'] = 0\n",
    "        j += 1. ## it was added here \n",
    "    ## Now for the 10 day rolling averages\n",
    "    roll_ten_am = namez[i]['pct'].rolling(10, min_periods = 1).mean()\n",
    "    namez[i]['rolling1'] = roll_ten_am\n",
    "\n",
    "\n",
    "    for j in range(9, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'var10'] = namez[i].loc[j-9:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar10']= np.cov(namez[i].loc[j-9:j,'pct'], namez[i].loc[j-9:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar10'] != 0:\n",
    "            namez[i].loc[j,'beta10'] = namez[i].loc[j,'covar10']/namez[i].loc[j,'var10']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta10'] = 0\n",
    "\n",
    "        j += 1\n",
    "    \n",
    "    for j in range(9, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'var10'] = namez[i].loc[j-9:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar10']= np.cov(namez[i].loc[j-9:j,'pct'], namez[i].loc[j-9:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar10'] != 0:\n",
    "            namez[i].loc[j,'beta10'] = namez[i].loc[j,'covar10']/namez[i].loc[j,'var10']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta10'] = 0\n",
    "        \n",
    "        j += 1\n",
    "  ## 20 day averages and things\n",
    "\n",
    "    roll_twty_am = namez[i]['pct'].rolling(20, min_periods = 1).mean()\n",
    "    namez[i]['rolling20'] = roll_twty_am\n",
    "\n",
    "\n",
    "    namez[i]['var20'] = 0\n",
    "    namez[i]['covar20'] = 0\n",
    "    namez[i]['beta20'] = 0\n",
    "    for j in range(19, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'var20'] = namez[i].loc[j-19:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar20']= np.cov(namez[i].loc[j-19:j,'pct'], namez[i].loc[j-19:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar20'] != 0:\n",
    "            namez[i].loc[j,'beta20'] = namez[i].loc[j,'covar20']/namez[i].loc[j,'var20']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta20'] = 0\n",
    "        j += 1\n",
    "        \n",
    "## Thirty Days\n",
    "\n",
    "    roll_thrt_am = namez[i]['pct'].rolling(30, min_periods = 1).mean()\n",
    "    namez[i]['rolling30'] = roll_thrt_am\n",
    "\n",
    "\n",
    "\n",
    "    namez[i]['var30'] = 0\n",
    "    namez[i]['covar30'] = 0\n",
    "    namez[i]['beta30'] = 0\n",
    "    for j in range(29, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'var30'] = namez[i].loc[j-29:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar30']= np.cov(namez[i].loc[j-29:j,'pct'], namez[i].loc[j-29:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar30'] != 0:\n",
    "            namez[i].loc[j,'beta30'] = namez[i].loc[j,'covar30']/namez[i].loc[j,'var30']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta50'] = 0   \n",
    "        j += 1\n",
    "        \n",
    "## Rolling 50 day\n",
    "    roll_ffty_am = namez[i]['pct'].rolling(50, min_periods = 1).mean()\n",
    "    namez[i]['rolling50'] = roll_ffty_am\n",
    "    \n",
    "    namez[i]['varfifty'] = 0\n",
    "    namez[i]['covarfifty'] = 0\n",
    "    namez[i]['betafifty'] = 0\n",
    "    for j in range(64, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'varfifty'] = namez[i].loc[j-64:j,'pct'].var()\n",
    "        namez[i].loc[j,'covarfifty']= np.cov(namez[i].loc[j-64:j,'pct'], namez[i].loc[j-64:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covarfifty'] != 0:\n",
    "            namez[i].loc[j,'betafifty'] = namez[i].loc[j,'covarfifty']/namez[i].loc[j,'varfifty']\n",
    "        else:\n",
    "            namez[i].loc[j,'betafifty'] = 0                 \n",
    "        j += 1\n",
    "        \n",
    "        \n",
    "## 250 calendar days - 178 market days\n",
    "\n",
    "    roll_250_am = namez[i]['pct'].rolling(250, min_periods = 1).mean()\n",
    "    namez[i]['rolling250'] = roll_250_am\n",
    "\n",
    "\n",
    "        \n",
    "    namez[i]['var250'] = 0\n",
    "    namez[i]['covar250'] = 0\n",
    "    namez[i]['beta250'] = 0\n",
    "    for j in range(178, namez[i].shape[0]):\n",
    "        namez[i].loc[j,'var250'] = namez[i].loc[j-178:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar250']= np.cov(namez[i].loc[j-178:j,'pct'], namez[i].loc[j-178:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar250'] != 0:\n",
    "            namez[i].loc[j,'beta250'] = namez[i].loc[j,'covar250']/namez[i].loc[j,'var250']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta250'] = 0 \n",
    "\n",
    "        j += 1\n",
    "        \n",
    "    namez[i] = namez[i].dropna(axis=0) \n",
    "    namez[i].reset_index(drop = True, inplace = True)\n",
    "##    print(namez[i].head())\n",
    "##    print(namez[i].shape)\n",
    "    i = i+1\n",
    "    \n",
    " \n",
    " ## Rolling 250 day\n",
    "\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"\\nthis finished at \", now)\n",
    "\n",
    "\n",
    "sp500_df = namez[2]\n",
    "ndaq_df = namez[1]\n",
    "djia_df = namez[0]\n",
    "\n",
    "sp500_df.to_csv(\"spy500_df.csv\", header = True)\n",
    "print(\"the head of sp500_df is \\n\", sp500_df.head())\n",
    "ndaq_df.to_csv(\"ndaq_df.csv\", header = True)\n",
    "djia_df.to_csv(\"djia__df.csv\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for Tesla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for Apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everbridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinder Morgan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shopify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanofy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McKormick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crude Oil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspire - as INSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowdstrike Holding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nothing to see here, just some old debugging for finding the file with the fewest rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketz = ['DJIA','NDAQ','^GSPC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n The stawk I'm doing is  AMZN\n",
      "/n The stawk I'm doing is  TSLA\n",
      "/n The stawk I'm doing is  AAPL\n",
      "/n The stawk I'm doing is  EVBG\n",
      "/n The stawk I'm doing is  KMI\n",
      "/n The stawk I'm doing is  SHOP\n",
      "/n The stawk I'm doing is  GMED\n",
      "/n The stawk I'm doing is  SNY\n",
      "/n The stawk I'm doing is  MCK\n",
      "/n The stawk I'm doing is  ET\n",
      "/n The stawk I'm doing is  INSP\n",
      "/n The stawk I'm doing is  CRWD\n",
      "/n The stawk I'm doing is  CL=F\n",
      "/n The stawk I'm doing is  UVXY\n",
      "/n The stawk I'm doing is  GLD\n",
      "/n The stawk I'm doing is  GBTC\n",
      "\n",
      " This finished at  2022-07-16 14:53:34.145022\n"
     ]
    }
   ],
   "source": [
    "stawkz =['AMZN',\n",
    "         'TSLA','AAPL','EVBG','KMI','SHOP','GMED','SNY','MCK',\n",
    "         'ET','INSP','CRWD','CL=F'\n",
    ", 'UVXY', 'GLD', 'GBTC']\n",
    "namez = ['AMZN_df',\n",
    "         'TSLA_df','AAPL_df','EVBG_df','KMI_df','SHOP_df','GMED_df','SNY_df',\n",
    "        'MCK_df','ET_df','INSP_df','CRWD_df','CL=F_df'\n",
    "##namez = ['AMZN_df','TSLA_df','AAPL_df','EVBG_df','KMI_df','SHOP_df','GMED_df','SNY_df',\n",
    "##         'MCK_df','ET_df','INSP_df','CL=F_df']\n",
    ", 'UVXY_df', 'GLD_df', 'GBTC_df']\n",
    "\n",
    "i =0\n",
    "for stawk in stawkz:\n",
    "    yahoo_financials = YahooFinancials(stawk)\n",
    "\n",
    "    print(\"/n The stawk I'm doing is \", stawk)\n",
    "    data = yahoo_financials.get_historical_price_data(start_date= minus_fifteen_years, \n",
    "                                                  end_date= whats_today, \n",
    "                                                  time_interval='daily')\n",
    "   \n",
    "    namez[i] = pd.DataFrame(data[stawk]['prices'])\n",
    "    namez[i] = namez[i].drop('date', axis=1)\n",
    "\n",
    "##    print(\"the shape of sp500_df is \\n\", sp500_df.shape)\n",
    "##    print(\"i is \", i, \"and namez[i] is \\n\", namez[i].head())\n",
    "\n",
    "    ##sp500_df.reset_index(drop = True)\n",
    "    ##djia_df.reset_index(drop = True)\n",
    "    ##ndaq_df.reset_index(drop = True)\n",
    "    \n",
    "##    print(\"the head of sp500 is \\n\", sp500_df.head())\n",
    "    \n",
    "    barky = namez[i]['adjclose']\n",
    "    namez[i]['pct'] = barky.pct_change(1)\n",
    "    roll_3_am =namez[i]['pct'].rolling(3, min_periods = 1).mean()\n",
    "    namez[i]['rolling3'] = roll_3_am\n",
    "    namez[i] = namez[i].dropna(axis=0) \n",
    "    namez[i].reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "    \n",
    "    ## three day rolling averages\n",
    "\n",
    "    namez[i]['var3'] = 0\n",
    "    namez[i]['covar3'] = 0\n",
    "    namez[i]['beta3'] = 0\n",
    "    namez[i]['var10'] = 0\n",
    "    namez[i]['covar10']= 0\n",
    "    namez[i]['beta10'] = 0\n",
    "    \n",
    "    k = min(namez[i].shape[0], ndaq_df.shape[0], sp500_df.shape[0], djia_df.shape[0])\n",
    "\n",
    "    for j in range(2, k):\n",
    "        namez[i].loc[j,'var3'] = namez[i].loc[j-2:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar3']= np.cov(sp500_df.loc[j-2:j,'pct'], namez[i].loc[j-2:j,'pct'])[0][1]\n",
    "\n",
    "        if namez[i].loc[j,'covar3'] != 0:\n",
    "            namez[i].loc[j,'beta3_clf'] = namez[i].loc[j,'covar3']/namez[i].loc[j,'var3']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta3_clf'] = 0\n",
    "            namez[i].loc[j,'covar3']= np.cov(ndaq_df.loc[j-2:j,'pct'], namez[i].loc[j-2:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar3'] != 0:\n",
    "            namez[i].loc[j,'beta3_ndaq'] = namez[i].loc[j,'covar3']/namez[i].loc[j,'var3']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta3_ndaq'] = 0\n",
    "        \n",
    "        namez[i].loc[j,'covar3']= np.cov(djia_df.loc[j-2:j,'pct'], namez[i].loc[j-2:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar3'] != 0:\n",
    "            namez[i].loc[j,'beta3_djia'] = namez[i].loc[j,'covar3']/namez[i].loc[j,'var3']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta3_djia'] = 0\n",
    "       \n",
    "        j += 1\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    ## Now for the 10 day rolling averages\n",
    "    namez[i]['var10'] = 0\n",
    "    namez[i]['covar10']= 0\n",
    "\n",
    "\n",
    "\n",
    "    roll_ten_am = namez[i]['pct'].rolling(10, min_periods = 1).mean()\n",
    "    namez[i]['rolling1'] = roll_ten_am\n",
    "\n",
    "    namez[i]['beta10_clf'] = 0\n",
    "    namez[i]['beta10_djia'] = 0\n",
    "    namez[i]['beta10_ndaq'] = 0\n",
    "    for j in range(9, k):\n",
    "        namez[i].loc[j,'var10'] = namez[i].loc[j-9:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar10']= np.cov(sp500_df.loc[j-9:j,'pct'], namez[i].loc[j-9:j,'pct'])[0][1]\n",
    "\n",
    "        if namez[i].loc[j,'covar10'] != 0:\n",
    "            namez[i].loc[j,'beta10_clf'] = namez[i].loc[j,'covar10']/namez[i].loc[j,'var10']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta10_clf'] = 0\n",
    "        namez[i].loc[j,'covar10']= np.cov(ndaq_df.loc[j-9:j,'pct'], namez[i].loc[j-9:j,'pct'])[0][1]\n",
    "        if namez[i].loc[i,'covar10'] != 0:\n",
    "            namez[i].loc[j,'beta10_ndaq'] = namez[i].loc[j,'covar10']/namez[i].loc[j,'var10']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta3_ndaq'] = 0\n",
    "        \n",
    "        namez[i].loc[j,'covar10']= np.cov(djia_df.loc[j-9:j,'pct'], namez[i].loc[j-9:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar10'] != 0:\n",
    "            namez[i].loc[j,'beta10_djia'] = namez[i].loc[j,'covar10']/namez[i].loc[j,'var10']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta10_djia'] = 0\n",
    "       \n",
    "        j += 1\n",
    "  ## 20 day averages and things\n",
    "\n",
    "    roll_twty_am = namez[i]['pct'].rolling(20, min_periods = 1).mean()\n",
    "    namez[i]['rolling20'] = roll_twty_am\n",
    "\n",
    "\n",
    "    namez[i]['var20'] = 0\n",
    "    namez[i]['covar20'] = 0\n",
    "    namez[i]['beta20_clf'] = 0\n",
    "    namez[i]['beta20_djia'] = 0\n",
    "    namez[i]['beta20_ndaq'] = 0\n",
    "\n",
    "    for j in range(19, k):\n",
    "        namez[i].loc[j,'var20'] = namez[i].loc[j-19:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar20']= np.cov(sp500_df.loc[j-19:j,'pct'], namez[i].loc[j-19:j,'pct'])[0][1]\n",
    "\n",
    "        if namez[i].loc[j,'covar20'] != 0:\n",
    "            namez[i].loc[j,'beta20_clf'] = namez[i].loc[j,'covar20']/namez[i].loc[j,'var20']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta20_clf'] = 0\n",
    "        namez[i].loc[j,'covar20']= np.cov(ndaq_df.loc[j-19:j,'pct'], namez[i].loc[j-19:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar20'] != 0:\n",
    "            namez[i].loc[j,'beta20_ndaq'] = namez[i].loc[j,'covar20']/namez[i].loc[j,'var20']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta20_ndaq'] = 0\n",
    "        \n",
    "        namez[i].loc[j,'covar20']= np.cov(djia_df.loc[j-19:j,'pct'], namez[i].loc[j-19:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar20'] != 0:\n",
    "            namez[i].loc[j,'beta20_djia'] = namez[i].loc[i,'covar20']/namez[i].loc[j,'var20']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta20_djia'] = 0\n",
    "       \n",
    "        j += 1\n",
    "        \n",
    "        \n",
    "## Thirty Days\n",
    "\n",
    "    roll_thrt_am = namez[i]['pct'].rolling(30, min_periods = 1).mean()\n",
    "    namez[i]['rolling30'] = roll_thrt_am\n",
    "\n",
    "\n",
    "\n",
    "    namez[i]['var30'] = 0\n",
    "    namez[i]['covar30'] = 0\n",
    "    namez[i]['beta30_clf'] = 0\n",
    "    namez[i]['beta30_djia'] = 0\n",
    "    namez[i]['beta30_ndaq'] = 0\n",
    "\n",
    "    for j in range(29, k):\n",
    "        namez[i].loc[j,'var30'] = namez[i].loc[j-29:j,'pct'].var()\n",
    "        namez[i].loc[j,'covar30']= np.cov(sp500_df.loc[j-29:j,'pct'], namez[i].loc[j-29:j,'pct'])[0][1]\n",
    "\n",
    "        if namez[i].loc[j,'covar30'] != 0:\n",
    "            namez[i].loc[j,'beta30_clf'] = namez[i].loc[j,'covar30']/namez[i].loc[j,'var30']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta30_clf'] = 0\n",
    "        namez[i].loc[j,'covar30']= np.cov(ndaq_df.loc[j-29:j,'pct'], namez[i].loc[j-29:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar30'] != 0:\n",
    "            namez[i].loc[j,'beta30_ndaq'] = namez[i].loc[j,'covar30']/namez[i].loc[j,'var30']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta30_ndaq'] = 0\n",
    "        \n",
    "        namez[i].loc[j,'covar30']= np.cov(djia_df.loc[j-29:j,'pct'], namez[i].loc[j-29:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covar30'] != 0:\n",
    "            namez[i].loc[j,'beta30_djia'] = namez[i].loc[j,'covar30']/namez[i].loc[j,'var30']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta30_djia'] = 0\n",
    "        j += 1       \n",
    "\n",
    "        \n",
    "## Rolling 50 day\n",
    "    roll_ffty_am = namez[i]['pct'].rolling(50, min_periods = 1).mean()\n",
    "    namez[i]['rolling50'] = roll_ffty_am\n",
    "    \n",
    "    namez[i]['varfifty'] = 0\n",
    "    namez[i]['covarfifty'] = 0\n",
    "    namez[i]['betafifty'] = 0\n",
    "    for j in range(64, k):\n",
    "        namez[i].loc[j,'varqrtr'] = namez[i].loc[j-64:j,'pct'].var()\n",
    "        namez[i].loc[j,'covarqrtr']= np.cov(sp500_df.loc[j-64:j,'pct'], namez[i].loc[j-64:j,'pct'])[0][1]\n",
    "\n",
    "        if namez[i].loc[j,'covarqrtr'] != 0:\n",
    "            namez[i].loc[j,'betaqtr_clf'] = namez[i].loc[j,'covarqrtr']/namez[i].loc[j,'varqrtr']\n",
    "        else:\n",
    "            namez[i].loc[j,'beta30_clf'] = 0\n",
    "        namez[i].loc[j,'covarqrtr']= np.cov(ndaq_df.loc[j-64:j,'pct'], namez[i].loc[j-64:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covarqrtr'] != 0:\n",
    "            namez[i].loc[j,'betaqtr_ndaq'] = namez[i].loc[j,'covarqrtr']/namez[i].loc[j,'varqrtr']\n",
    "        else:\n",
    "            namez[i].loc[j,'betaqtr_ndaq'] = 0\n",
    "        \n",
    "        namez[i].loc[j,'covarqrtr']= np.cov(djia_df.loc[j-64:j,'pct'], namez[i].loc[j-64:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covarqrtr'] != 0:\n",
    "            namez[i].loc[j,'betaqtr_djia'] = namez[i].loc[j,'covarqrtr']/namez[i].loc[j,'varqrtr']\n",
    "        else:\n",
    "            namez[i].loc[j,'betaqtr_djia'] = 0\n",
    "        j += 1            \n",
    "              \n",
    "\n",
    "## 250 calendar days - 178 stawk days\n",
    "\n",
    "    roll_250_am = namez[i]['pct'].rolling(250, min_periods = 1).mean()\n",
    "    namez[i]['rolling250'] = roll_250_am\n",
    "\n",
    "\n",
    "        \n",
    "    namez[i]['varyear'] = 0\n",
    "    namez[i]['covaryear'] = 0\n",
    "\n",
    "    namez[i]['betayr_clf'] = 0\n",
    "    namez[i]['betayr_ndaq'] = 0\n",
    "    namez[i]['betayr_djia'] = 0\n",
    "\n",
    "    for j in range(259, k):\n",
    "        namez[i].loc[j,'varyear'] = namez[i].loc[j-259:j,'pct'].var()\n",
    "        namez[i].loc[j,'covaryear']= np.cov(sp500_df.loc[j-259:j,'pct'], namez[i].loc[j-259:j,'pct'])[0][1]\n",
    "\n",
    "        if namez[i].loc[j,'covaryear'] != 0:\n",
    "            namez[i].loc[j,'betayr_clf'] = namez[i].loc[j,'covaryear']/namez[i].loc[j,'varyear']\n",
    "        else:\n",
    "            namez[i].loc[j,'betayr_clf'] = 0\n",
    "        namez[i].loc[j,'covaryear']= np.cov(ndaq_df.loc[j-259:j,'pct'], namez[i].loc[j-259:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covaryear'] != 0:\n",
    "            namez[i].loc[j,'betayr_ndaq'] = namez[i].loc[j,'covaryear']/namez[i].loc[j,'varyear']\n",
    "        else:\n",
    "            namez[i].loc[j,'betayr_ndaq'] = 0\n",
    "        \n",
    "        namez[i].loc[j,'covaryear']= np.cov(djia_df.loc[j-259:j,'pct'], namez[i].loc[j-259:j,'pct'])[0][1]\n",
    "        if namez[i].loc[j,'covaryear'] != 0:\n",
    "            namez[i].loc[j,'betayr_djia'] = namez[i].loc[j,'covaryear']/namez[i].loc[j,'varyear']\n",
    "        else:\n",
    "            namez[i].loc[j,'betayr_djia'] = 0\n",
    "        j += 1\n",
    "                \n",
    "                \n",
    "    namez[i] = namez[i].dropna(axis=0) \n",
    "    namez[i].reset_index(drop = True, inplace = True)\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    " \n",
    " ## Rolling 250 day\n",
    "\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"\\n This finished at \", now)\n",
    "\n",
    "amzn_df = namez[0]\n",
    "amzn_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/amzn_stock_df.csv\", header = True)\n",
    "tsla_df = namez[1]\n",
    "tsla_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/tsla_stock_df.csv\", header = True)\n",
    "aapl_df = namez[2]\n",
    "aapl_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/appl_stock_df.csv\", header = True)\n",
    "evbg_df = namez[3]\n",
    "evbg_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/evbg_stock_df.csv\", header = True)\n",
    "kmi_df = namez[4]\n",
    "kmi_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/kmi_stock_df.csv\", header = True)\n",
    "shop_df = namez[5]\n",
    "shop_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/shop_stock_df.csv\", header = True)\n",
    "gmed_df = namez[6]\n",
    "gmed_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/gmed_stock_df.csv\", header = True)\n",
    "sny_df = namez[7]\n",
    "sny_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/sny_stock_df.csv\", header = True)\n",
    "mck_df = namez[8]\n",
    "mck_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/mck_stock_df.csv\", header = True)\n",
    "et_df = namez[9]\n",
    "et_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/et_stock_df.csv\", header = True)\n",
    "insp_df = namez[10]\n",
    "insp_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/insp_stock_df.csv\", header = True)\n",
    "crwd_df = namez[11]\n",
    "crwd_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Filescrwd_stock_df.csv\", header = True)\n",
    "clf_df = namez[12]\n",
    "clf_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/clf_stock_df.csv\", header = True)\n",
    "UVXY_df = namez[12]\n",
    "UVXY_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/UVXY_etf_df.csv\", header = True)\n",
    "GLD_df = namez[13]\n",
    "GLD_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/GLD_etf_df.csv\", header = True)\n",
    "GBTC_df = namez[14]\n",
    "GBTC_df.to_csv(\"/Volumes/Elements/GitHub/twitter-project/Data_Files/GBTC_etf_df.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         high         low        open       close     volume    adjclose  \\\n",
      "0  137.811493  135.606995  136.977493  137.729004   59374000  137.729004   \n",
      "1  139.128494  134.399994  138.753006  134.643494  130016000  134.643494   \n",
      "2  134.839996  131.503998  134.500504  134.018997   84468000  134.018997   \n",
      "3  138.481506  133.751495  134.253494  137.940994   75394000  137.940994   \n",
      "4  144.750000  137.699997  137.899506  143.934998  127268000  143.934998   \n",
      "\n",
      "  formatted_date       pct  rolling3      var3  ...  covarqrtr  betaqtr_clf  \\\n",
      "0     2020-06-25  0.007380  0.005055  0.000222  ...   0.000003    -0.135438   \n",
      "1     2020-06-26 -0.022403 -0.008626  0.000225  ...   0.000012    -0.139316   \n",
      "2     2020-06-29 -0.004638 -0.006554  0.000225  ...   0.000018    -0.100336   \n",
      "3     2020-06-30  0.029264  0.000741  0.000689  ...   0.000025    -0.063186   \n",
      "4     2020-07-01  0.043453  0.022693  0.000611  ...   0.000020    -0.055112   \n",
      "\n",
      "   betaqtr_ndaq  betaqtr_djia  rolling250  varyear  covaryear  betayr_clf  \\\n",
      "0     -0.220918      0.005716    0.005648        0          0           0   \n",
      "1     -0.179742      0.023968    0.005223        0          0           0   \n",
      "2     -0.166246      0.037466    0.005076        0          0           0   \n",
      "3     -0.085619      0.054478    0.005431        0          0           0   \n",
      "4     -0.052715      0.043050    0.005982        0          0           0   \n",
      "\n",
      "   betayr_ndaq  betayr_djia  \n",
      "0            0            0  \n",
      "1            0            0  \n",
      "2            0            0  \n",
      "3            0            0  \n",
      "4            0            0  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "the date and time is  2022-07-16 14:53:34.259719\n"
     ]
    }
   ],
   "source": [
    "print(namez[0].head())\n",
    "\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "print(\"the date and time is \",time_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha is actual rate of return minus expected rate of return\n",
    "\n",
    "Find T-bill data, find S&P 500 return over time , so risk premium is S&P500 - T-bill rate of retun\n",
    "the use beta\n",
    "expected rate is risk free rate (T-Bill) + beta *(market return - risk free rate)\n",
    "\n",
    "Then find the actual rate of return \n",
    "\n",
    "Then alpha is actual return minus expected rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yahoo_financials = YahooFinancials('TB4WK')\n",
    "\n",
    "data = yahoo_financials.get_historical_price_data(start_date= minus_fifteen_years, \n",
    "                                                  end_date= whats_today, \n",
    "                                                  time_interval='daily')\n",
    "week_13_t_bill = pd.DataFrame(data['TB4WK'])\n",
    " \n",
    "\n",
    "print(\"/n The shape is \", week_13_t_bill.shape)\n",
    "\n",
    "\n",
    "##    print(\"the shape of sp500_df is \\n\", sp500_df.shape)\n",
    "##    print(\"i is \", i, \"and namez[i] is \\n\", namez[i].head())\n",
    "\n",
    "    ##sp500_df.reset_index(drop = True)\n",
    "    ##djia_df.reset_index(drop = True)\n",
    "    ##ndaq_df.reset_index(drop = True)\n",
    "    \n",
    "##    print(\"the head of sp500 is \\n\", sp500_df.head())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n The head is  (0, 1)\n"
     ]
    }
   ],
   "source": [
    "week_13_t_bill = pd.DataFrame(data['TB4WK'])\n",
    "##week_13_t_bill = week_13_t_bill.drop('date', axis=1)  \n",
    "\n",
    "print(\"/n The head is \", week_13_t_bill.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('for_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "15723ea50007c9eb518e398a0ca0130bc4bd2586315387ed6566b7a3b6eabae5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
